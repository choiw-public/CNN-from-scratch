{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This implementation is slow because GPU is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist # pip install mnist\n",
    "import utils\n",
    "import operations as op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:\n",
    "np.random.seed(0)\n",
    "batch_size = 100\n",
    "total_iteration = 500\n",
    "\n",
    "lr = 0.1 # learning rate\n",
    "weight_decay = 0.0001\n",
    "optimizer = 'gradient_descent'  # optional: momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:\n",
    "# Define CNN model modified from LeNet5\n",
    "# os.FC : fully connected layer \n",
    "\n",
    "# Usage\n",
    "# op.Convolution(kernel_size, channel_in, channel_out, stride, use_bias)\n",
    "# op.Pooling(kernel_size, stride, pooling_type=['average' or 'max'])\n",
    "# os.FC(node_in, node_out, use_bias)\n",
    "model_np = [op.Convolution(3, 1, 2, 1, False),\n",
    "            op.BatchNormalization(),\n",
    "            op.ReLU(),\n",
    "\n",
    "            op.Pool(3, 2, 'average'),\n",
    "            op.ReLU(),\n",
    "\n",
    "            op.Convolution(3, 2, 4, 1, False),\n",
    "            op.BatchNormalization(),\n",
    "            op.ReLU(),\n",
    "\n",
    "            op.Pool(3, 2, 'average'),\n",
    "            op.ReLU(),\n",
    "\n",
    "            op.Convolution(3, 4, 128, 1, False),\n",
    "            op.BatchNormalization(),\n",
    "            op.ReLU(),\n",
    "\n",
    "            op.FC(512, 32, False),\n",
    "            op.BatchNormalization(),\n",
    "            op.ReLU(),\n",
    "\n",
    "            op.FC(32, 10, False)]\n",
    "softmax_np = op.Softmax()\n",
    "loss_np = op.CrossEntropy()  # loss\n",
    "cost_np = op.Cost()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0050 | cost:0.285,  accuracy:0.95\n",
      "iter:0100 | cost:0.256,  accuracy:0.94\n",
      "iter:0150 | cost:0.199,  accuracy:0.93\n",
      "iter:0200 | cost:0.188,  accuracy:0.95\n",
      "iter:0250 | cost:0.132,  accuracy:0.97\n",
      "iter:0300 | cost:0.172,  accuracy:0.94\n",
      "iter:0350 | cost:0.094,  accuracy:0.98\n",
      "iter:0400 | cost:0.085,  accuracy:0.97\n",
      "iter:0450 | cost:0.141,  accuracy:0.96\n",
      "iter:0500 | cost:0.086,  accuracy:0.99\n"
     ]
    }
   ],
   "source": [
    "# prepare train data\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "\n",
    "args = {'lr': lr, 'is_train': True, 'optimizer': optimizer, 'weight_decay': weight_decay}\n",
    "for iteration in range(total_iteration):\n",
    "    random_indices = np.random.randint(0, len(train_images), batch_size)\n",
    "    x_np = np.expand_dims(train_images[random_indices, ::] / 255.0, 3).astype(np.float32)\n",
    "    y_np = utils.one_hot_encode(train_labels[random_indices], 10)\n",
    "    args['y'] = y_np\n",
    "\n",
    "    # forward\n",
    "    out_np = x_np\n",
    "    l2_loss = 0\n",
    "    for layer in model_np:\n",
    "        layer.forward(out_np, args)\n",
    "        try:\n",
    "            l2_loss += layer.l2_los\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        out_np = layer.value\n",
    "    softmax_np.forward(out_np, args)\n",
    "    loss_np.forward(softmax_np.value, args)\n",
    "    cost_np.forward(loss_np.value, l2_loss)\n",
    "    pred_np = np.argmax(model_np[-1].value, 1)\n",
    "    accuracy_np = np.mean(pred_np == np.argmax(y_np, 1))\n",
    "    \n",
    "    # backward\n",
    "    cost_np.backward()\n",
    "    loss_np.backward(cost_np.grads)\n",
    "    softmax_np.backward(loss_np.grads)\n",
    "    grads_np = softmax_np.grads\n",
    "    for layer in model_np[::-1]:\n",
    "        layer.backward(grads_np, args)\n",
    "        grads_np = layer.grads\n",
    "    if (iteration+1) % 50 == 0:\n",
    "        print(\"iter:%04d | cost:%.3f,  accuracy:%.2f\" % (iteration+1, cost_np.value, accuracy_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing (01000/10000)\n",
      "Testing (02000/10000)\n",
      "Testing (03000/10000)\n",
      "Testing (04000/10000)\n",
      "Testing (05000/10000)\n",
      "Testing (06000/10000)\n",
      "Testing (07000/10000)\n",
      "Testing (08000/10000)\n",
      "Testing (09000/10000)\n",
      "Testing (10000/10000)\n",
      "accuracy: 0.966\n"
     ]
    }
   ],
   "source": [
    "# prepare test data\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "correctness = 0.0\n",
    "args['is_train'] = False # to use moving mean and variance\n",
    "for i, (test_img, test_label) in enumerate(zip(test_images, test_labels)):\n",
    "    x_np = (test_img.reshape([1, 28, 28, 1]) / 255.0).astype(np.float32)\n",
    "    y_np = utils.one_hot_encode(test_label.reshape(1, 1), 10)\n",
    "    # forward\n",
    "    out_np = x_np\n",
    "    for layer in model_np:\n",
    "        layer.forward(out_np, args)\n",
    "        out_np = layer.value\n",
    "    pred_np = np.argmax(out_np, 1)\n",
    "    correctness += np.sum(pred_np == test_label)\n",
    "    if (i+1) % 1000 == 0:\n",
    "        print(\"Testing (%05d/%05d)\"%(i+1, len(test_images)))\n",
    "print(\"accuracy: %.3f\" % (correctness / len(test_images)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
